{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import hinge_loss\n",
    "cols=['iteration','C','Margin','Train_hinge_loss','cost_training','Test_hinge_loss','cost_testing']\n",
    "lst=[]\n",
    "for i in range (1,1001):\n",
    "    (X, y) = make_blobs(n_samples=[2000,2000], n_features=2, centers=[(-0.5,0 ),(0.5,0)],cluster_std=[0.05,0.05], random_state=i)\n",
    "    y = np.where(y == 1, 1, -1)\n",
    "   \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=1)\n",
    "\n",
    "    #plt.title(\"Train Dataset,σ=%.2f,i=%.0f\"%(σ,i))\n",
    "    i=i\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    from sklearn import svm\n",
    "    import numpy as np\n",
    " \n",
    "    Cs= np.logspace(-2,2,1000).tolist()\n",
    " \n",
    "    Cs=np.array(Cs)\n",
    "    clf = svm.SVC(kernel='linear', C=Cs)\n",
    "    \n",
    "    #i=[]\n",
    "    C=[]\n",
    "    Margin=[]\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    number_of_misclassified_train_points=[]\n",
    "    number_of_misclassified_test_points=[]\n",
    "    Train_hinge_loss=[]\n",
    "    cost_training=[]\n",
    "    Test_hinge_loss=[]\n",
    "    cost_testing=[]\n",
    "    \n",
    "    #alphas=[]\n",
    "    #ξs=[]\n",
    "    \n",
    "    #old_M=0\n",
    "    #old_C=0\n",
    "    #old_train=0\n",
    "    #old_test=0\n",
    "    #old_misclassified_train=0\n",
    "    #old_misclassified_test=0\n",
    "\n",
    "    for C in Cs:\n",
    "        \n",
    "        clf.set_params(C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        #C.append(C)\n",
    "        i=i\n",
    "        w = clf.coef_[0]\n",
    "        #Weights.append(w)\n",
    "        \n",
    "        y_train_predict=clf.predict(X_train)\n",
    "        train_error=metrics.mean_squared_error(y_train,y_train_predict)\n",
    "        train_errors.append(train_error)\n",
    "        \n",
    "        misclassified_train=np.where(y_train != y_train_predict)\n",
    "        number_of_misclassified_train_points.append(misclassified_train)\n",
    "       \n",
    "        \n",
    "        y_test_predict=clf.predict(X_test)\n",
    "        test_error=metrics.mean_squared_error(y_test,y_test_predict)\n",
    "        test_errors.append(test_error)\n",
    "        \n",
    "        misclassified_test=np.where(y_test != y_test_predict)\n",
    "        number_of_misclassified_test_points.append(misclassified_test)\n",
    "        \n",
    "        pred_decision_train = clf.decision_function(X_train)\n",
    "        hinge_loss_train=hinge_loss(y_train,pred_decision_train)\n",
    "        Train_hinge_loss.append(hinge_loss_train)\n",
    "\n",
    "        pred_decision_test = clf.decision_function(X_test)\n",
    "        hinge_loss_test=hinge_loss(y_test,pred_decision_test)\n",
    "        Test_hinge_loss.append(hinge_loss_test)\n",
    "        \n",
    "        cost_train=1/2* np.dot(w,w)+C* hinge_loss_train\n",
    "        cost_training.append(cost_train)\n",
    "        \n",
    "        cost_test=1/2* np.dot(w,w)+ C*hinge_loss_test\n",
    "        cost_testing.append(cost_test)\n",
    "        \n",
    "        #alpha=clf.dual_coef_\n",
    "        #alphas.append(alpha)\n",
    "        #ξ=y_train*clf.decision_function(X_train)\n",
    "        #ξs.append(ξ)\n",
    "        a = -w[0] / w[1]\n",
    "        M= 2 / np.sqrt(np.sum(w ** 2))\n",
    "        Margin.append(M)\n",
    "        #if M!=old_M:\n",
    "            #old_M=M\n",
    "            #old_C=C\n",
    "            #old_train=train_error\n",
    "            #old_test=test_error\n",
    "            #old_misclassified_train=len(misclassified_train[0])\n",
    "            #old_misclassified_test=len(misclassified_test[0])\n",
    "        #else:\n",
    "            #break\n",
    "        #lst.append([i,C,Margin,train_errors,number_of_misclassified_train_points,test_errors,number_of_misclassified_test_points,Train_hinge_loss,cost_training,Test_hinge_loss,cost_testing])    \n",
    "        lst.append([i,C,M,hinge_loss_train,cost_train,hinge_loss_test,cost_test])    \n",
    " \n",
    "    #print ('iteration=%.f'%i)\n",
    "    #print (old_C,old_M)\n",
    "    \n",
    "    #print (\"C\")\n",
    "    #print (Cs)\n",
    "    #print (\"Margin\")\n",
    "    #print (Margin)\n",
    "    #print (\"MSE_Train\")\n",
    "    #print (train_errors)\n",
    "    #print (\"MSE_Test\")\n",
    "    #print (test_errors)\n",
    "    #print (\"ξ\")\n",
    "    #print (ξs)\n",
    "    #print (\"number_of_misclassified_train_points\")\n",
    "    #print (number_of_misclassified_train_points)\n",
    "    #print (\"number_of_misclassified_test_points\")\n",
    "    #print (number_of_misclassified_test_points)\n",
    "df = pd.DataFrame(lst, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel (r'C:\\Users\\i49ahmed\\Downloads\\FinalTest\\Avg\\BadC.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
